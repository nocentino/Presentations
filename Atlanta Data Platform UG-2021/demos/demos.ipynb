{
    "metadata": {
        "kernelspec": {
            "name": "powershell",
            "display_name": "PowerShell",
            "language": "powershell"
        },
        "language_info": {
            "name": "powershell",
            "codemirror_mode": "shell",
            "mimetype": "text/x-sh",
            "file_extension": ".ps1"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "**Demo Setup...run the first and second cell before the session**"
            ],
            "metadata": {
                "azdata_cell_guid": "53c5e963-ed5b-439a-9d6c-a6a8402571b3"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "$ENV:KUBECONFIG='/Users/aen/.kube/arc-config'\n",
                "kubectl config get-contexts\n",
                "kubectl config set-context kubernetes-admin\n",
                "kubectl get nodes"
            ],
            "metadata": {
                "azdata_cell_guid": "93995c3e-1310-4366-b8f1-92eaa1e779b2",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "CURRENT   NAME                          CLUSTER      AUTHINFO           NAMESPACE\n          kubernetes-admin                                              \n*         kubernetes-admin@kubernetes   kubernetes   kubernetes-admin   \n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "Context \"kubernetes-admin\" modified.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "NAME    STATUS   ROLES    AGE   VERSION\narc01   Ready    master   22d   v1.18.3\n",
    "output_type": "stream"
}
],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "$ENV:AZDATA_USERNAME='arcadmin'\n",
                "$ENV:AZDATA_PASSWORD='S0methingS@Str0ng!'\n",
                "\n",
                "azdata login --endpoint https://172.16.94.14:30080 --namespace arc\n",
                "\n",
                "azdata arc sql mi create -n sqldemo01"
            ],
            "metadata": {
                "azdata_cell_guid": "ff22ff07-ba2a-449d-8c63-b34133a0fd76"
            },
            "outputs": [
{
    "name": "stdout",
    "text": "Logged in successfully to `https://172.16.94.14:30080` in namespace `arc`. Setting active context to `arc`.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "ERROR: Arc SQL managed instance `sqldemo01` already exists in namespace `arc`.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**First up, let's log into our Azure Arc Data Controller using the Azure Data CLI ( `azdata` )**\n",
                "The Kubernetes cluster we're using is local on my laptop here and we will integrate this with Azure using Indirect Connectivity Mode"
            ],
            "metadata": {
                "azdata_cell_guid": "62cb517a-00c1-4765-9431-c680e32480af"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "$ENV:AZDATA_USERNAME='arcadmin'\n",
                "$ENV:AZDATA_PASSWORD='S0methingS@Str0ng!'\n",
                "\n",
                "azdata login --endpoint https://172.16.94.14:30080 --namespace arc"
            ],
            "metadata": {
                "azdata_cell_guid": "fc8c1305-3bbf-4260-b355-99001a9f310c",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "Logged in successfully to `https://172.16.94.14:30080` in namespace `arc`. Setting active context to `arc`.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "**As with any CLI tool, your first stop should be the help :) Get familiar with the syntax and options available.**"
            ],
            "metadata": {
                "azdata_cell_guid": "5d783509-9daf-4101-a131-540739d7a3fa"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc --help"
            ],
            "metadata": {
                "azdata_cell_guid": "dbc40c6a-fbc7-4a59-837d-d510e86adb3c",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "\nGroup\n    azdata arc : Commands for using Azure Arc for Azure data services.\n\nSubgroups:\n    dc            : Create, delete, and manage data controllers.\n    postgres      : Create, delete, and managed Azure Arc enabled PostgreSQL Hyperscale server\n                    groups.\n    resource-kind : Resource-kind commands to define and template custom resources on your cluster.\n    sql           : Create, delete, and manage SQL resources.\n\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**I've  already deployed one Managed Instance and one PostgreSQL Hyperscale instance into our Arc Data Services on premises environment. To get connection information we can use `azdata`.**"
            ],
            "metadata": {
                "azdata_cell_guid": "0ba40889-9e24-451c-a52d-5aefd1258b1f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc sql --help\n",
                "azdata arc sql mi list"
            ],
            "metadata": {
                "azdata_cell_guid": "07b0806e-eded-4acf-9550-dff676c50bd2",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "\nGroup\n    azdata arc sql : Create, delete, and manage SQL resources.\n\nSubgroups:\n    endpoint : View and manage SQL endpoints.\n    mi       : Create, delete, and manage SQL managed instance.\n\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "ExternalEndpoint    Name       Replicas    State\n------------------  ---------  ----------  -------\n172.16.94.14,31501  sqldemo01  1/1         Ready\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "source": [
                "kubectl get services --namespace arc"
            ],
            "metadata": {
                "azdata_cell_guid": "97c7cf7d-e1fb-4445-93d5-54896bef7188"
            },
            "outputs": [
{
    "name": "stdout",
    "text": "NAME                      TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                                       AGE\ncontroldb-svc             ClusterIP   10.105.201.254   <none>        1433/TCP,8311/TCP,8411/TCP                    3h24m\ncontroller-svc            ClusterIP   10.98.89.150     <none>        443/TCP,8311/TCP,8301/TCP,8411/TCP,8401/TCP   3h24m\ncontroller-svc-external   NodePort    10.101.71.249    <none>        8443:30080/TCP                                3h24m\nlogsdb-svc                ClusterIP   10.109.71.166    <none>        9200/TCP,8300/TCP,8400/TCP                    3h23m\nlogsui-svc                ClusterIP   10.103.245.221   <none>        5601/TCP,8300/TCP,8400/TCP                    3h23m\nmetricsdb-svc             ClusterIP   10.99.122.152    <none>        8086/TCP,8300/TCP,8400/TCP                    3h23m\nmetricsdc-svc             ClusterIP   10.104.176.66    <none>        8300/TCP,8400/TCP                             3h23m\nmetricsui-svc             ClusterIP   10.106.44.1      <none>        3000/TCP,8300/TCP,8400/TCP                    3h23m\nmgmtproxy-svc             ClusterIP   10.104.216.212   <none>        443/TCP,8300/TCP,8311/TCP,8400/TCP,8411/TCP   3h23m\nmgmtproxy-svc-external    NodePort    10.108.204.79    <none>        8443:30777/TCP                                3h23m\nsqldemo01-external-svc    NodePort    10.106.24.143    <none>        1433:31501/TCP                                162m\nsqldemo01-svc             ClusterIP   None             <none>        1433/TCP                                      162m\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Let's get the Port (NodePort) for our deployed Managed Instance which is backed by the Service `sqldemo01-external-svc`**\n",
                "\n",
                "**Here is an example of being able to use kubernetes native tooling**"
            ],
            "metadata": {
                "azdata_cell_guid": "4229429b-15fd-4bbe-8b5a-111fbdb79421"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "$NodePort=kubectl get services --namespace arc sqldemo01-external-svc -o jsonpath='{ .spec.ports[0].nodePort }'\n",
                "sqlcmd -S 172.16.94.14,$NodePort -U arcadmin -P 'S0methingS@Str0ng!' -Q 'SELECT @@VERSION'"
            ],
            "metadata": {
                "azdata_cell_guid": "a95dedc5-8463-4410-85b4-dd345590d47c",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "                                                                                                                                                                                                                                                                                                            \n------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\nMicrosoft Azure SQL Database Managed Instance - Azure Arc - 15.0.2000.532 (X64) \n\tSep 10 2020 03:08:27 \n\tCopyright (C) 2019 Microsoft Corporation\n\tDeveloper Edition (64-bit) on Linux (Ubuntu 16.04.7 LTS) <X64>                                                                                           \n\n(1 rows affected)\n",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Let's check out the help command for creating a Managed Instance**"
            ],
            "metadata": {
                "azdata_cell_guid": "fb5bcccb-5daa-4929-96f7-7bf4fc525bf5"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc sql mi create --help"
            ],
            "metadata": {
                "azdata_cell_guid": "33305e71-201b-4673-9431-376d0080bcb9"
            },
            "outputs": [
{
    "name": "stdout",
    "text": "\nCommand\n    azdata arc sql mi create : Create a SQL managed instance.\n        To set the password of the SQL managed instance, please set the environment variable\n        AZDATA_PASSWORD.\n\nArguments\n    --name -n            [Required] : The name of the SQL managed instance.\n    --cores-limit -cl               : The cores limit of the managed instance as an integer.\n    --cores-request -cr             : The request for cores of the managed instance as an integer.\n    --memory-limit -ml              : The limit of the capacity of the managed instance as an\n                                      integer.\n    --memory-request -mr            : The request for the capcity of the managed instance as an\n                                      integer amount of memory in GBs.\n    --no-external-endpoint          : If specified, no external service will be created. Otherwise,\n                                      an external service will be created using the same service\n                                      type as the data controller.\n    --no-wait                       : If given, the command will not wait for the instance to be in\n                                      a ready state before returning.\n    --path                          : The path to the src file for the SQL managed instance json\n                                      file.\n    --replicas                      : The number of replicas to be deployed for high availability\n                                      purpose. Allowed values are '3' or '1' with default of '1'.\n    --storage-class-backups -scb    : The storage class to be used for backups\n                                      (/var/opt/mssql/backups). If no value is specified, then no\n                                      storage class will be specified, which will result in\n                                      Kubernetes using the default storage class.\n    --storage-class-data -scd       : The storage class to be used for data (.mdf). If no value is\n                                      specified, then no storage class will be specified, which will\n                                      result in Kubernetes using the default storage class.\n    --storage-class-data-logs -scdl : The storage class to be used for database logs (.ldf). If no\n                                      value is specified, then no storage class will be specified,\n                                      which will result in Kubernetes using the default storage\n                                      class.\n    --storage-class-logs -scl       : The storage class to be used for logs (/var/log). If no value\n                                      is specified, then no storage class will be specified, which\n                                      will result in Kubernetes using the default storage class.\n    --volume-size-backups -vsb      : The size of the storage volume to be used for backups as a\n                                      positive number followed by Ki (kilobytes), Mi (megabytes), or\n                                      Gi (gigabytes).\n    --volume-size-data -vsd         : The size of the storage volume to be used for data as a\n                                      positive number followed by Ki (kilobytes), Mi (megabytes), or\n                                      Gi (gigabytes).\n    --volume-size-data-logs -vsdl   : The size of the storage volume to be used for data logs as a\n                                      positive number followed by Ki (kilobytes), Mi (megabytes), or\n                                      Gi (gigabytes).\n    --volume-size-logs -vsl         : The size of the storage volume to be used for logs as a\n                                      positive number followed by Ki (kilobytes), Mi (megabytes), or\n                                      Gi (gigabytes).\n\nGlobal Arguments\n    --debug                         : Increase logging verbosity to show all debug logs.\n    --help -h                       : Show this help message and exit.\n    --output -o                     : Output format.  Allowed values: json, jsonc, table, tsv.\n                                      Default: json.\n    --query                         : JMESPath query string. See http://jmespath.org/ for more\n                                      information and examples.\n    --verbose                       : Increase logging verbosity. Use --debug for full debug logs.\n\nExamples\n    Create a SQL managed instance.\n        azdata arc sql mi create -n sqlmi1\n\n\n    Create a SQL managed instance with 3 replicas in HA scenario.\n        azdata arc sql mi create -n sqlmi2 --replicas 3\n\n\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**We can create one with minimal options which will get you a Managed Instance with no CPU or Memory limits and Requests of 100m and 100Mi and a single disk from your default StorageClass. Takes about 1 minute with containers pre-pulled.**"
            ],
            "metadata": {
                "azdata_cell_guid": "8e4f0bb9-5e98-4393-a20d-09ba372510fb"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc sql mi create --name sqldemo02 "
            ],
            "metadata": {
                "azdata_cell_guid": "9506ddae-7514-497b-95b1-05f38ff3979b",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "Using AZDATA_USERNAME environment variable for `sqldemo02` username.\nUsing AZDATA_PASSWORD environment variable for `sqldemo02` password.\n",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Let's check out our newly deployed Managed Instance. Now we have two unique Service Endpoints.**"
            ],
            "metadata": {
                "azdata_cell_guid": "132bd1a6-00cc-4cf9-8e98-690577164ea2"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc sql mi list "
            ],
            "metadata": {
                "azdata_cell_guid": "5822049d-ad60-42e7-82d6-f152c77dc657",
                "tags": []
            },
            "outputs": [
{
    "name": "stdout",
    "text": "ExternalEndpoint    Name       Replicas    State\n------------------  ---------  ----------  --------\n172.16.94.14,31501  sqldemo01  1/1         Ready\n172.16.94.14,32252  sqldemo02  0/1         Creating\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Now with all of that let's check out some of the management tooling and to do that...let's upload some data into Azure.** \n",
                "\n",
                "**You can use environment variables to help build automation around these tools.** \n",
                "\n",
                "**Otherwise the prompts are going to be interactive...asking for things like username, namespace, workspace\\_id and so on.**"
            ],
            "metadata": {
                "azdata_cell_guid": "f7a7c043-9826-4b82-b02b-7b9204b98328"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "$env:AZDATA_USERNAME=\"arcadmin\"\n",
                "$env:AZDATA_PASSWORD=\"S0methingS@Str0ng!\"\n",
                "$env:SUB_ID='fd0c5e48-eea6-4b37-a076-0e23e0df74cb'\n",
                "$env:SPN_CLIENT_ID='a7b906f4-297f-4aaa-821d-a410e398973e'\n",
                "$env:SPN_CLIENT_SECRET='9gp9DlIG-vhEwPdggrGMMbmMUnnCplEyRU'\n",
                "$env:SPN_TENANT_ID='f17cbd44-7697-453e-941c-efe0a4c2d55a'\n",
                "$env:SPN_AUTHORITY='https://login.microsoftonline.com'\n",
                "$env:WORKSPACE_ID=\"31f660e3-cb32-4f1c-97f1-e69896eca90f\"\n",
                "$env:WORKSPACE_SHARED_KEY=\"TNeKgNLo67T9+8dAN1oDdBzrdwiIdJJ/HD1dwbWRCuWIbyuET/SR/ZpUtkRQvkZxYxrYgB+9niNzXQxAZMQdkg==\"\n",
                "\n",
                "azdata login --endpoint https://172.16.94.14:30080 --namespace arc\n",
                "\n",
                "azdata arc dc export --type metrics --path metrics.json --force && azdata arc dc upload --path metrics.json\n",
                "azdata arc dc export --type logs --path logs.json --force && azdata arc dc upload --path logs.json"
            ],
            "metadata": {
                "azdata_cell_guid": "135307e1-df53-4879-8fd7-023360fcd690"
            },
            "outputs": [
{
    "name": "stdout",
    "text": ". {\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": ">> $env:AZDATA_USERNAME=\"arcadmin\"\n>> $env:AZDATA_PASSWORD=\"S0methingS@Str0ng!\"\n>> $env:SUB_ID='fd0c5e48-eea6-4b37-a076-0e23e0df74cb'\n>> $env:SPN_CLIENT_ID='a7b906f4-297f-4aaa-821d-a410e398973e'\n>> $env:SPN_CLIENT_SECRET='9gp9DlIG-vhEwPdggrGMMbmMUnnCplEyRU'\n>> $env:SPN_TENANT_ID='f17cbd44-7697-453e-941c-efe0a4c2d55a'\n>> $env:SPN_AUTHORITY='https://login.microsoftonline.com'\n>> $env:WORKSPACE_ID=\"31f660e3-cb32-4f1c-97f1-e69896eca90f\"\n>> $env:WORKSPACE_SHARED_KEY=\"TNeKgNLo67T9+8dAN1oDdBzrdwiIdJJ/HD1dwbWRCuWIbyuET/SR/ZpUtkRQvkZxYxrYgB+9niNzXQxAZMQdkg==\"\n>> \n>> azdata login --endpoint https://172.16.94.14:30080 --namespace arc\n>> \n>> azdata arc dc export --type metrics --path metrics.json --force && azdata arc dc upload --path metrics.json\n>> azdata arc dc export --type logs --path logs.json --force && azdata arc dc upload --path logs.json\n>> }\n>> \n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "Logged in successfully to `https://172.16.94.14:30080` in namespace `arc`. Setting active context to `arc`.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "This option exports metrics of all instances in \"arc\" to the file: \"metrics.json\".\nCollecting metrics for SQLMANAGEDINSTANCES instance: 'arc.sqldemo01'\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "\t Successfully got metric: 'CPU Usage'\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "\t Successfully got metric: 'Memory Usage'\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "\t Successfully got metric: 'Transactions/second'\n\n\nMetrics are exported to metrics.json\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "\t\"arc\" is uploaded to Azure \"/subscriptions/fd0c5e48-eea6-4b37-a076-0e23e0df74cb/resourcegroups/arc-onprem/providers/Microsoft.AzureArcData/dataControllers/arc\"\n\t\"sqldemo01\" has been uploaded to Azure \"/subscriptions/fd0c5e48-eea6-4b37-a076-0e23e0df74cb/resourcegroups/arc-onprem/providers/Microsoft.AzureArcData/sqlManagedInstances/sqldemo01\".\n\n\nAzure resource_id: /subscriptions/fd0c5e48-eea6-4b37-a076-0e23e0df74cb/resourcegroups/arc-onprem/providers/Microsoft.AzureArcData/sqlManagedInstances/sqldemo01\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "Metrics upload pushed 85 data points successfully.\n\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "This option exports logs of all instances in \"arc\" to the file: \"logs.json\".\nStart retrieving last 1 days of logs for sqlManagedInstances instance \"sqldemo01\", this may take some time...\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "\tCollected 0 logs from UTC '2021-03-08 23:40Z' to '2021-03-09 00:52Z'\nNo log is exported.\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "ERROR: Cannot find file: \"logs.json\". Please provide the correct file name and try again\n",
    "output_type": "stream"
}, {
    "name": "stdout",
    "text": "",
    "output_type": "stream"
}
],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Management, Monitoring and Logging** - our implementation of Azure Arc Enabled Data Services is Indirectly Connected. The local tools hold the metrics, logging and usage data. One uploaded, you can use tools in Azure to analyze that data. Let's look at the local tools then hop into Azure to look at the tools available there. Install the Azure Arc ADS Extension.\n",
                "1. Right click Manage to Launch the **Azure Arc Data Controller Dashboard**\n",
                "    \n",
                "    - Click on the Managed Instance **sqldemo01** to launch the management dashboard\n",
                "    - To view logs on-prem click **Kibana Dashboard**\n",
                "        - Set the date range to 15 days ago and search for **master** and **tempdb**\n",
                "    - To view Metrics on-prem click **Grafana Dashboard**\n",
                "        - Review the core SQL Server metrics\n",
                "2. Back on the main **Azure Arc Data Controller Dashboard**, notice the Connection mode of the Data Controller: **Indirect**. Click on **Open in Azure Portal**.\n",
                "    \n",
                "3. Click on the Resource Group name in our case it's **arc-onprem**\n",
                "    \n",
                "4. Check out the resources in the Portal\n",
                "    \n",
                "    - Click on Metrics, change the **Metric Namespace** to `sql server` **change the Metric** to `Memory Usage`. change the date range to 24 hours.\n",
                "5. In the Log Analytics workspace and run the following query\n",
                "    \n",
                "    - ```\n",
                "           sqlManagedInstances_logs_CL |  where TimeGenerated > ago(7d)  |  order by TimeGenerated desc \n",
                "        ```"
            ],
            "metadata": {
                "azdata_cell_guid": "1dcd5e8e-1876-4848-82c6-5cd6269bdf67"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "azdata arc sql mi delete --name sqldemo02\n",
                "azdata arc sql mi delete --name sqldemo01\n",
                "azdata arc postgres server delete --name postgres01\n",
                "azdata logout"
            ],
            "metadata": {
                "azdata_cell_guid": "752e3b6f-a8cf-4a0e-a7ef-7e9eaff1c33d",
                "tags": []
            },
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "markdown",
            "source": [
                "**Everything deployed inside of Azure Arc Data Services is implemented as a Kubernetes Object...let's check out a few.** \n",
                "\n",
                "-   **Pods** - running container based applications inside the Kubernetes cluster\n",
                "-   **Services** - access endpoints to reach the applications running inside our cluster. There can be cluster internal (ClusterIP) and external Service endpoints (NodePort). Can be integrated with external LoadBalancers if needed.\n",
                "-   **DaemonSets** - ensure a Pod is running on each node in the cluster. Used by the Metrics data collector in Arc, in our case [Telegraf](https://github.com/influxdata/telegraf \"https://github.com/influxdata/telegraf\").\n",
                "-   **ReplicaSets** -  ensure a desired number of Pods are running in the cluster.  Primarily used by management software and web ports for logs and metrics (bootstrapper, control, controlwd, logsui, metricsui and mgmtproxy)\n",
                "-   **StatefulSets** - ensure a desired number of Pods are running in the cluster. But also provide stable naming on the Pods and cluster service discovery via Cluster DNS. Used by controldb, logsdb, metricsdb and also provisioned Managed Instances and Postgres instances. Enables scaling."
            ],
            "metadata": {
                "azdata_cell_guid": "aace495c-60c2-47af-8911-f42db0cc858f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "kubectl get all --namespace arc"
            ],
            "metadata": {
                "azdata_cell_guid": "96adca0d-b964-4cbd-88cc-42e8e8de17c7",
                "tags": [
                    "hide_input"
                ]
            },
            "outputs": [],
            "execution_count": null
        }
    ]
}